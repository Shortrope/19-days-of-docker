# Deploying Stateful Services

## Stateful Services and Storage Drivers
### Stateless Pods:
- Do not have any state or changing date that must be stored
- Data is stored/retrieved from external starages

### Stateful Pods:
- Have state and need to store data
- Require persistent file system across Pod terminiation/recreation

### Persistent Volume
- Can be provided as a file system to Pods
- Lifecycle is independent from Pods
- Can be accessed by multiple Pods at once

### Choosing a Network Storage Technology
Two basic types of Network Storage
1. Network Block Devices
1. Network File Systems

#### Network Block Devices
- Key Features:
  - Fast
  - Fixed size
  - Can be used by one Pod at a time
- Self-hosted:
  - iSCSI
  - Rados Block Devices (Ceph)

#### Network File Systems
- Key Features
  - Slower than Block Devices
  - Can be used by many Pods simultaneously
- Self-hosted:
  - NFS
  - CephFS
  - GlusterFS

You can use more than one storage tech in your cluster as needed  
Lerarn more about _Ceph_: [learning Ceph (packt pub)](https://www.packtpub.com/virtualization-and-cloud/learning-ceph-second-edition)

## Working w Persistent Volumes
To use a Persistent Volume (PV)
- The PV must be created
  - Provisioned and made available by a Cluster Operator
- The PV must be claimed for use in one or more Pods
  - PersistenVolumeClaim (PVC)
  - Created by the application/service user/deployer

### Creating a PersistentVolume and Claim
1. Create the PV
1. Create the PVC
1. Use the PVC when defining a Pod

<br>
1. Create the PV:  
File _pv.yml_

    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: my-volume
    spec:
      capacity:
        storage: 10Gi
      accessModes:
        - ReadWriteOnce
      awsElasticBlockStore:
        volumeID: vol-9812387750901374
        fsType: ext4
Access modes:
- ReadWriteOnce: One Pod at a time
- ReadWriteMany: Many Pods at a time

If using Minikube, you cannot use these cluster storage technologies.  
But can use the local storage  
<br>
_Do NOT do this in production_

    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: my-volume
    spec:
      capacity:
        storage: 10Gi
      accessModes:
        - ReadWriteOnce
      hostPath:
      path: /data/myvolume
<br>
2. Create the PVC:  

File _pvc.yml_  

    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: my-volume-claim
    spec:
      resources:
        requests:
          storage: 10Gi
      accessModes:
        - ReadWriteOnce
<br>
3. Use the PVC in a pod, replicaSet or Deployment 

File _my-database.yml_

    apiVersion: v1
    kind: Pod
    metadata:
      name: my-database
    spec:
      containers:
        - name: database
          image: mysql:5.7
          env:
            # ...
          volumeMounts:
            - mountPath: /var/lib/mysql
              name: data
      volumes:
        - name: data
          persistentVolumeClaim: 
            claimName: my-volume-claim

Implement the yaml files

    kubectl apply -f pv.yml
    kubectl apply -f pvc.yml
    kubectl apply -f my-database.yml
    kubectl get pv
    kubectl get pvc

## Automatic Volume Provisioning
### Storage Class  

_Storage Class_ 
- Contains the definition of a persistant volume  
- The PVC references a _Storage Class_  

_Volume Provisioner_ 
- Automatically creates the PersistantVolume based on the StorageClass
- Binds the PV to the PVC

StorageClass yaml

    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: ssd-fast
    provisioner: kubernetes.io/aws-ebs
    parameters:
      type: io1
      zones: ..
      iopsPerGB: ..

PVC w StorageClass 

    apiVersion: v1
    kind: PersistantVolumeClaim
    metadata:
      name: my-volume-claim
    spec:
      storageClass: ssd-fast
      resources:
        requests:
          storage: 10Gi
      accessModes:
        - ReadWriteOnce

View StorageClasses

    kubectl get storageclass

Kubernetes provides a large set of _provisioners_

## Using StatefulSets
- Manage Pods and their associated _Persistant Volumes_
- Self-healing and scalable
- Ideal for clustered apps